{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run singles subject ICA on single session for artefact rejection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The script is:\n",
      "# - importing DICOMS into 3D NIFTI (for now done manually with Labnic's Matlab function)\n",
      "# - convert 3D Nifti to 4D\n",
      "# - run FSL FEAT function to realignement and filter data (no smoothing, no normalization ( = coregistration)\n",
      "# - run melodic ICA\n",
      "\n",
      "import nipype.pipeline.engine as pe\n",
      "import nipype.interfaces.io as nio\n",
      "import nipype.interfaces.fsl as fsl\n",
      "import nipype.interfaces.utility as util     # utility\n",
      "import os\n",
      "import glob \n",
      "\n",
      "fsl.FSLCommand.set_default_output_type('NIFTI_GZ')\n",
      "\n",
      "#---------------------------------------------------------------------------------------------------------#\n",
      "#                      Define subject and session list and expe directory\n",
      "#\n",
      "#---------------------------------------------------------------------------------------------------------#\n",
      "\n",
      "#SUBJ_LIST = [\"S02\", \"S03\", \"S04\", \"S05\", \"S06\", \"S07\", \"S08\", \"S09\", \"S10\", \"S11\", \"S12\", \"S13\", \"S14\", \"S15\", \"S16\", \"S17\", \"S18\", \"S19\", \"S20\"] \n",
      "subject_list = [\"S02\"] \n",
      "session_list = [\"hypno1\"] #, \"painloc_hypno\", \"hypno1\", \"hypno2\", \"norm1\", \"norm2\"\n",
      "expe_dir = os.path.abspath('/media/claire/Data/EMPATHYP_DATA/Subjects')\n",
      "\n",
      "#---------------------------------------------------------------------------------------------------------#\n",
      "#                      Define directory architecture and path variables to access the files\n",
      "#\n",
      "#---------------------------------------------------------------------------------------------------------#\n",
      "\n",
      "# define node Identity Interface to specify the list of subjects the pipeline should be executed on\n",
      "infosource= pe.Node(util.IdentityInterface(fields = ['subject_id', 'session']), name = 'infosource') # give the variable names in the path to iterate on \n",
      "infosource.iterables = ([('subject_id', subject_list), ('session', session_list)])\n",
      "\n",
      "# node datagrabber: to grab the input data\n",
      "datasource = pe.Node(nio.DataGrabber(infields = ['subject_id', 'session' ], outfields = ['out_files']), name = 'datasource') # \n",
      "datasource.inputs.base_directory = expe_dir # name of working directory\n",
      "datasource.inputs.template = '%s/ICA/%s/*.nii'   #path to access data from working directory, takes Data Grabber infields as variables\n",
      "datasource.inputs.sort_filelist = False # mandatory field\n",
      "\n",
      "# Node datasink: create data sink node to store important output\n",
      "datasink = pe.Node(nio.DataSink(), name = \"datasink\")\n",
      "datasink.inputs.base_directory = os.path.abspath(expe_dir + 'subject_id' + 'ICA' + 'session') \n",
      "datasink.inputs.container = 'session' + '_ica'  # define where the data sink input should be stored at                   \n",
      "\n",
      "#---------------------------------------------------------------------------------------------------------#\n",
      "#                      Define functions to process the files\n",
      "#\n",
      "#---------------------------------------------------------------------------------------------------------#\n",
      "\n",
      "# node to merge all nii to 4D nii\n",
      "merger = pe.Node(fsl.Merge(dimension = 't', \n",
      "                              output_type = 'NIFTI_GZ',\n",
      "                               tr = 2.1),  # glob.glob('*.nii')\n",
      "                               name = 'merge nii in 4D',\n",
      "                               #iterfield = ['in_file']\n",
      "                               )\n",
      "\n",
      "\n",
      "\n",
      "#---------------------------------------------------------------------------------------------------------#\n",
      "#                      Define workflow connection between functions\n",
      "#\n",
      "#---------------------------------------------------------------------------------------------------------#\n",
      "\n",
      "\n",
      "preproc = pe.Workflow(name='preproc')                                          \n",
      "# connect workflow\n",
      "preproc.connect([(infosource, datasource,[('subject_id', 'subject_id'), ('session', 'session')] ), #gives 2 inputs (subject id and sessin) to each infosource and datasource \n",
      "                 (datasource, merger, [('out_files', 'in_files')]), # the output of datasource (outfiles) is used as input to merger (in_files)\n",
      "                 (merger, datasink, [('merged_file', 'toto')])]) # the output of merger (merged_files)  is used as input to datasink to go in folder toto\n",
      "preproc.run()\n",
      "\n",
      "\n",
      "#---------------------------------------------------------------------------------------------------------#\n",
      "#                      Export graph of the workflow\n",
      "#\n",
      "#---------------------------------------------------------------------------------------------------------#\n",
      "\n",
      "preproc.write_graph(\"ica_workflow_graph.dot\")\n",
      "from IPython.display import Image\n",
      "Image(filename = \"ica_workflow_graph.dot.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "Exception",
       "evalue": "the name must not contain any special characters",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-1b88bef87825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m                               \u001b[0moutput_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'NIFTI_GZ'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                tr = 2.1),  # glob.glob('*.nii')\n\u001b[0;32m---> 55\u001b[0;31m                                \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'merge nii in 4D'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                                \u001b[0;31m#iterfield = ['in_file']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                                )\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/nipype/pipeline/engine.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, interface, name, iterables, itersource, synchronize, overwrite, needed_outputs, run_without_submitting, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'base_dir'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Interface must be provided'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/nipype/pipeline/engine.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, base_dir)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# for compatibility with node expansion using iterables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/nipype/pipeline/engine.pyc\u001b[0m in \u001b[0;36m_verify_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mvalid_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^[\\w-]+$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'the name must not contain any special characters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mException\u001b[0m: the name must not contain any special characters"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(mnio.DataGrabber.help()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Generic datagrabber module that wraps around glob in an\n",
        "intelligent way for neuroimaging tasks to grab files\n",
        "\n",
        "\n",
        ".. attention::\n",
        "\n",
        "   Doesn't support directories currently\n",
        "\n",
        "Examples\n",
        "--------\n",
        "\n",
        ">>> from nipype.interfaces.io import DataGrabber\n",
        "\n",
        "Pick all files from current directory\n",
        "\n",
        ">>> dg = DataGrabber()\n",
        ">>> dg.inputs.template = '*'\n",
        "\n",
        "Pick file foo/foo.nii from current directory\n",
        "\n",
        ">>> dg.inputs.template = '%s/%s.dcm'\n",
        ">>> dg.inputs.template_args['outfiles']=[['dicomdir','123456-1-1.dcm']]\n",
        "\n",
        "Same thing but with dynamically created fields\n",
        "\n",
        ">>> dg = DataGrabber(infields=['arg1','arg2'])\n",
        ">>> dg.inputs.template = '%s/%s.nii'\n",
        ">>> dg.inputs.arg1 = 'foo'\n",
        ">>> dg.inputs.arg2 = 'foo'\n",
        "\n",
        "however this latter form can be used with iterables and iterfield in a\n",
        "pipeline.\n",
        "\n",
        "Dynamically created, user-defined input and output fields\n",
        "\n",
        ">>> dg = DataGrabber(infields=['sid'], outfields=['func','struct','ref'])\n",
        ">>> dg.inputs.base_directory = '.'\n",
        ">>> dg.inputs.template = '%s/%s.nii'\n",
        ">>> dg.inputs.template_args['func'] = [['sid',['f3','f5']]]\n",
        ">>> dg.inputs.template_args['struct'] = [['sid',['struct']]]\n",
        ">>> dg.inputs.template_args['ref'] = [['sid','ref']]\n",
        ">>> dg.inputs.sid = 's1'\n",
        "\n",
        "Change the template only for output field struct. The rest use the\n",
        "general template\n",
        "\n",
        ">>> dg.inputs.field_template = dict(struct='%s/struct.nii')\n",
        ">>> dg.inputs.template_args['struct'] = [['sid']]\n",
        "\n",
        "Inputs::\n",
        "\n",
        "\t[Mandatory]\n",
        "\tsort_filelist: (a boolean)\n",
        "\t\tSort the filelist that matches the template\n",
        "\ttemplate: (a string)\n",
        "\t\tLayout used to get files. relative to base directory if defined\n",
        "\n",
        "\t[Optional]\n",
        "\tbase_directory: (an existing directory name)\n",
        "\t\tPath to the base directory consisting of subject data.\n",
        "\tignore_exception: (a boolean, nipype default value: False)\n",
        "\t\tPrint an error message instead of throwing an exception in case the\n",
        "\t\tinterface fails to run\n",
        "\traise_on_empty: (a boolean, nipype default value: True)\n",
        "\t\tGenerate exception if list is empty for a given field\n",
        "\tsort_filelist: (a boolean)\n",
        "\t\tSort the filelist that matches the template\n",
        "\ttemplate: (a string)\n",
        "\t\tLayout used to get files. relative to base directory if defined\n",
        "\ttemplate_args: (a dictionary with keys which are a string and with\n",
        "\t\t values which are a list of items which are a list of items which\n",
        "\t\t are any value)\n",
        "\t\tInformation to plug into template\n",
        "\n",
        "Outputs::\n",
        "\n",
        "\tNone\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fsl.Merge.help()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wraps command **fslmerge**\n",
        "\n",
        "Use fslmerge to concatenate images\n",
        "\n",
        "Images can be concatenated across time, x, y, or z dimensions. Across the\n",
        "time (t) dimension the TR is set by default to 1 sec.\n",
        "\n",
        "Note: to set the TR to a different value, specify 't' for dimension and\n",
        "specify the TR value in seconds for the tr input. The dimension will be\n",
        "automatically updated to 'tr'.\n",
        "\n",
        "Examples\n",
        "--------\n",
        ">>> from nipype.interfaces.fsl import Merge\n",
        ">>> merger = Merge()\n",
        ">>> merger.inputs.in_files = ['functional2.nii', 'functional3.nii']\n",
        ">>> merger.inputs.dimension = 't'\n",
        ">>> merger.inputs.output_type = 'NIFTI_GZ'\n",
        ">>> merger.cmdline\n",
        "'fslmerge -t functional2_merged.nii.gz functional2.nii functional3.nii'\n",
        ">>> merger.inputs.tr = 2.25\n",
        ">>> merger.cmdline\n",
        "'fslmerge -tr functional2_merged.nii.gz functional2.nii functional3.nii 2.25'\n",
        "\n",
        "Inputs::\n",
        "\n",
        "\t[Mandatory]\n",
        "\tdimension: ('t' or 'x' or 'y' or 'z' or 'a')\n",
        "\t\tdimension along which to merge, optionally set tr input when\n",
        "\t\tdimension is t\n",
        "\tin_files: (a list of items which are an existing file name)\n",
        "\tterminal_output: ('stream' or 'allatonce' or 'file' or 'none')\n",
        "\t\tControl terminal output: `stream` - displays to terminal\n",
        "\t\timmediately, `allatonce` - waits till command is finished to display\n",
        "\t\toutput, `file` - writes output to file, `none` - output is ignored\n",
        "\n",
        "\t[Optional]\n",
        "\targs: (a string)\n",
        "\t\tAdditional parameters to the command\n",
        "\tdimension: ('t' or 'x' or 'y' or 'z' or 'a')\n",
        "\t\tdimension along which to merge, optionally set tr input when\n",
        "\t\tdimension is t\n",
        "\tenviron: (a dictionary with keys which are a value of type 'str' and\n",
        "\t\t with values which are a value of type 'str', nipype default value:\n",
        "\t\t {})\n",
        "\t\tEnvironment variables\n",
        "\tignore_exception: (a boolean, nipype default value: False)\n",
        "\t\tPrint an error message instead of throwing an exception in case the\n",
        "\t\tinterface fails to run\n",
        "\tin_files: (a list of items which are an existing file name)\n",
        "\tmerged_file: (a file name)\n",
        "\toutput_type: ('NIFTI_PAIR' or 'NIFTI_PAIR_GZ' or 'NIFTI_GZ' or\n",
        "\t\t 'NIFTI')\n",
        "\t\tFSL output type\n",
        "\tterminal_output: ('stream' or 'allatonce' or 'file' or 'none')\n",
        "\t\tControl terminal output: `stream` - displays to terminal\n",
        "\t\timmediately, `allatonce` - waits till command is finished to display\n",
        "\t\toutput, `file` - writes output to file, `none` - output is ignored\n",
        "\ttr: (a float)\n",
        "\t\tuse to specify TR in seconds (default is 1.00 sec), overrides\n",
        "\t\tdimension and sets it to tr\n",
        "\n",
        "Outputs::\n",
        "\n",
        "\tmerged_file: (an existing file name)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# map field names to individual subject runs\n",
      "info = dict(session=[['subject_id', ['NIFTI'], ['painloc_norm', 'painloc_hypno', 'hypno1', 'hypno2', 'norm1', 'norm2'], ['waf'] ]])\n",
      "\n",
      "\n",
      "infosource = pe.Node(interface=util.IdentityInterface(fields=['subject_id']),\n",
      "                     name=\"infosource\")\n",
      "\n",
      "infosource.iterables = ('subject_id', subject_list)\n",
      "\n",
      "datasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'],\n",
      "                                               outfields=['session']),\n",
      "                     name = 'datasource')\n",
      "datasource.inputs.base_directory = data_dir\n",
      "datasource.inputs.template = '%s/%s/%s/%s/*.ni.gz'\n",
      "datasource.inputs.template_args = info\n",
      "datasource.inputs.sort_filelist = True\n",
      "\n",
      "# create 4D Nifti\n",
      "merger = pe.Node(interface = fsl.Merge(in_files = nii_file, dimension = 't', output_type = 'NIFTI_GZ', tr = 2.1), name = 'merger')    \n",
      "\n",
      "\n",
      "# run ica\n",
      "#melodic = pe.Node(interface = fsl.Melodic(\n",
      "        \n",
      "ica_workflow = pe.Workflow(name=\"ica_workflow\") \n",
      "ica_workfow.connect([infosource, datasource, [('subject_id', 'subject_id')]),\n",
      "                     (merger, 'infile') # is sending the output of merger as an input to melodic\n",
      "                    ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}